# -*- coding: utf-8 -*-
"""
æ¨¡å‹æµ‹è¯•ç³»ç»Ÿæ¨¡å—

è´Ÿè´£é’ˆå¯¹ä»ProviderConfigManagerä¸­é€‰æ‹©çš„ç‰¹å®šæœåŠ¡å•†çš„æ¨¡å‹æ‰§è¡Œå¹¶å‘APIæµ‹è¯•ã€‚
"""

import http.client
import json
import time
import threading
import csv
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urlparse

from .utils.helpers import clear_console, extract_domain, format_timestamp, generate_filename, create_progress_bar
from .utils.error_handbook import parse_error, parse_exception


class ModelTestSystem:
    """
    æ¨¡å‹æµ‹è¯•ç³»ç»Ÿç±»
    
    è´Ÿè´£é’ˆå¯¹ç‰¹å®šæœåŠ¡å•†çš„æ¨¡å‹æ‰§è¡Œå¹¶å‘APIæµ‹è¯•ï¼Œä½¿ç”¨ç”±ProviderConfigManageræä¾›çš„é…ç½®è¯¦æƒ…ã€‚
    """
    
    # é»˜è®¤å…¨å±€æµ‹è¯•é…ç½®
    DEFAULT_GLOBAL_TEST_CONFIG = {
        'max_workers': 50,              # æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        'request_timeout': 30,          # å•æ¬¡APIè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        'max_retries': 3,               # å•ä¸ªæ¨¡å‹æµ‹è¯•çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        'global_timeout': 300,          # æµ‹è¯•æ€»è¿è¡Œæ—¶é—´ä¸Šé™ï¼ˆç§’ï¼‰
        'status_refresh': 0.2,          # çŠ¶æ€ç›‘æ§ç•Œé¢åˆ·æ–°é¢‘ç‡ï¼ˆç§’ï¼‰
        'test_prompt': {                # æ ‡å‡†åŒ–çš„æµ‹è¯•è´Ÿè½½JSONç»“æ„
            'messages': [
                {'role': 'user', 'content': 'Respond with \'OK\''}
            ],
            'model': 'placeholder',      # å°†åŠ¨æ€å¡«å……
            'temperature': 0.1,
            'max_tokens': 5
        }
    }
    
    def __init__(self, provider_config: Dict[str, Any], global_test_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹æµ‹è¯•ç³»ç»Ÿ
        
        Args:
            provider_config (Dict[str, Any]): ç”¨æˆ·ä»ProviderConfigManageré€‰æ‹©çš„å•ä¸ªæœåŠ¡å•†çš„é…ç½®å­—å…¸
            global_test_config (Optional[Dict[str, Any]], optional): å…¨å±€æµ‹è¯•é…ç½®å­—å…¸
        """
        self.provider_config = provider_config
        self.config = global_test_config or self.DEFAULT_GLOBAL_TEST_CONFIG
        
        # æå–æœåŠ¡å•†ä¿¡æ¯
        self.provider_name = provider_config['name']
        self.api_type = provider_config['api_type']
        self.base_url = provider_config.get('base_url', '')
        
        # é€‰æ‹©APIå¯†é’¥ï¼ˆç®€å•å®ç°ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªå¯†é’¥ï¼‰
        self.api_key = provider_config['api_keys'][0] if provider_config['api_keys'] else ''
        
        # è‡ªå®šä¹‰è¯·æ±‚å¤´
        self.custom_headers = provider_config.get('custom_headers', {})
        
        # ä»base_urlæå–åŸŸå
        self.domain = extract_domain(self.base_url)
        
        # è®¾ç½®HTTPè¯·æ±‚å¤´
        self.headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        # æ·»åŠ è‡ªå®šä¹‰è¯·æ±‚å¤´
        self.headers.update(self.custom_headers)
        
        # åˆå§‹åŒ–å†…éƒ¨çŠ¶æ€å˜é‡
        self.models_data = []  # é’ˆå¯¹å½“å‰é€‰å®šæœåŠ¡å•†çš„æ¨¡å‹æ•°æ®
        self.categories = {}   # å¦‚æœèƒ½ä»/modelsç«¯ç‚¹è·å–åˆ†ç±»ä¿¡æ¯
        
        # å¹¶å‘æ§åˆ¶å˜é‡
        self.status_lock = threading.Lock()
        self.progress_lock = threading.Lock()
        self.active_tasks = {}  # å½“å‰æ´»åŠ¨ä»»åŠ¡çŠ¶æ€
        self.should_stop = False  # å…¨å±€åœæ­¢æ ‡å¿—
        
        # è¿›åº¦ç»Ÿè®¡
        self.total_tasks = 0
        self.completed_tasks = 0
    
    def load_models_for_provider(self) -> bool:
        """
        åŠ è½½å½“å‰é€‰å®šæœåŠ¡å•†çš„æ¨¡å‹åˆ—è¡¨
        
        å°è¯•ä»æœåŠ¡å•†çš„APIç«¯ç‚¹è·å–æ¨¡å‹åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é…ç½®ä¸­çš„supported_models
        
        Returns:
            bool: åŠ è½½æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        # é¦–å…ˆæ£€æŸ¥provider_configä¸­çš„supported_models
        if 'supported_models' in self.provider_config and self.provider_config['supported_models']:
            self.models_data = [{'id': model_id} for model_id in self.provider_config['supported_models']]
            print(f"å·²ä»é…ç½®åŠ è½½ {len(self.models_data)} ä¸ªæ¨¡å‹")
            return True
        
        # å¦‚æœsupported_modelsä¸ºç©ºï¼Œå°è¯•ä»APIè·å–
        if not self.base_url:
            print("é”™è¯¯: æœªæä¾›base_urlï¼Œæ— æ³•ä»APIè·å–æ¨¡å‹åˆ—è¡¨")
            return False
        
        try:
            # ç¡®å®šæ¨¡å‹åˆ—è¡¨APIç«¯ç‚¹
            endpoint = '/v1/models'
            if self.api_type == 'azure-openai':
                # Azure OpenAI APIå¯èƒ½æœ‰ä¸åŒçš„ç«¯ç‚¹æ ¼å¼
                endpoint = '/openai/deployments?api-version=2023-05-15'
            
            # è§£æURL
            parsed_url = urlparse(self.base_url)
            conn = http.client.HTTPSConnection(parsed_url.netloc, timeout=self.config['request_timeout'])
            
            # å‘é€è¯·æ±‚
            conn.request('GET', endpoint, headers=self.headers)
            response = conn.getresponse()
            response_data = response.read().decode('utf-8')
            
            if response.status == 200:
                data = json.loads(response_data)
                
                # è§£æå“åº”æ•°æ®ï¼Œæ ¼å¼å¯èƒ½å› APIç±»å‹è€Œå¼‚
                if self.api_type == 'azure-openai':
                    # Azure OpenAI APIæ ¼å¼
                    self.models_data = data.get('data', [])
                else:
                    # æ ‡å‡†OpenAI APIæ ¼å¼
                    self.models_data = data.get('data', [])
                    
                    # å¦‚æœAPIè¿”å›ä¿¡æ¯åŒ…å«owned_byï¼Œå¯æ®æ­¤è¿›è¡Œåˆ†ç±»
                    for model in self.models_data:
                        if 'owned_by' in model:
                            category = model['owned_by']
                            if category not in self.categories:
                                self.categories[category] = []
                            self.categories[category].append(model['id'])
                
                # æŒ‰åç§°æ’åºæ¨¡å‹
                self.models_data.sort(key=lambda x: x.get('id', ''))
                
                print(f"å·²ä»APIåŠ è½½ {len(self.models_data)} ä¸ªæ¨¡å‹")
                return True
            else:
                error_info = parse_error(response.status, response_data)
                print(f"ä»APIè·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {error_info['error_category']} - {error_info['solution']}")
                return False
        
        except Exception as e:
            error_info = parse_exception(e)
            print(f"ä»APIè·å–æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {error_info['error_category']} - {error_info['solution']}")
            return False
    
    def _select_models_for_testing(self) -> List[str]:
        """
        äº¤äº’å¼æ¨¡å‹é€‰æ‹©èœå•
        
        åœ¨ç”¨æˆ·é€‰å®šä¸€ä¸ªæœåŠ¡å•†å¹¶åŠ è½½å…¶æ¨¡å‹åå‘ˆç°ï¼Œè®©ç”¨æˆ·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹
        
        Returns:
            List[str]: åŒ…å«å¾…æµ‹è¯•çš„å®é™…æ¨¡å‹IDçš„åˆ—è¡¨
        """
        try:
            import questionary
            from questionary import Choice
        except ImportError:
            print("é”™è¯¯: æœªå®‰è£…questionaryåº“ï¼Œæ— æ³•æ˜¾ç¤ºäº¤äº’å¼èœå•ã€‚è¯·ä½¿ç”¨pip install questionaryå®‰è£…ã€‚")
            return []
        
        if not self.models_data:
            print("é”™è¯¯: æœªåŠ è½½ä»»ä½•æ¨¡å‹ï¼Œè¯·å…ˆè°ƒç”¨load_models_for_provider()æ–¹æ³•")
            return []
        
        # å‡†å¤‡æ¨¡å‹é€‰æ‹©åˆ—è¡¨
        model_choices = []
        model_mappings = self.provider_config.get('model_mappings', {})
        
        # æ·»åŠ æ‰€æœ‰æ¨¡å‹é€‰é¡¹
        for model_data in self.models_data:
            model_id = model_data.get('id', '')
            if not model_id:
                continue
            
            # æŸ¥æ‰¾å‹å¥½åç§°ï¼ˆå¦‚æœå­˜åœ¨æ˜ å°„ï¼‰
            friendly_name = None
            for map_name, map_id in model_mappings.items():
                if map_id == model_id:
                    friendly_name = map_name
                    break
            
            # æ„å»ºæ˜¾ç¤ºåç§°
            display_name = model_id
            if friendly_name:
                display_name = f"{friendly_name} ({model_id})"
            
            model_choices.append(Choice(title=display_name, value=model_id))
        
        # æ·»åŠ ç‰¹æ®Šé€‰é¡¹
        model_choices.insert(0, Choice(title="æµ‹è¯•æ­¤æœåŠ¡å•†çš„æ‰€æœ‰å·²åŠ è½½æ¨¡å‹", value="ALL_MODELS"))
        model_choices.append(Choice(title="è¿”å›æœåŠ¡å•†é€‰æ‹©ç•Œé¢", value="BACK"))
        
        # æ˜¾ç¤ºé€‰æ‹©èœå•
        print(f"\næœåŠ¡å•† '{self.provider_name}' çš„å¯ç”¨æ¨¡å‹:")
        selection = questionary.select(
            "è¯·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹:",
            choices=model_choices
        ).ask()
        
        if selection == "BACK":
            return []
        elif selection == "ALL_MODELS":
            return [model.get('id') for model in self.models_data if model.get('id')]
        else:
            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šæ¨¡å‹ï¼Œåˆ™è¿”å›å•ä¸ªæ¨¡å‹IDçš„åˆ—è¡¨
            return [selection]
    
    def run_tests(self, models_to_test: List[str]) -> None:
        """
        è¿è¡Œæ¨¡å‹æµ‹è¯•
        
        Args:
            models_to_test (List[str]): è¦æµ‹è¯•çš„æ¨¡å‹IDåˆ—è¡¨
        """
        if not models_to_test:
            print("æ²¡æœ‰é€‰æ‹©ä»»ä½•æ¨¡å‹è¿›è¡Œæµ‹è¯•")
            return
        
        # åˆå§‹åŒ–è®¡æ•°å™¨å’ŒçŠ¶æ€å˜é‡
        self.total_tasks = len(models_to_test)
        self.completed_tasks = 0
        self.active_tasks = {}
        self.should_stop = False
        
        # åˆ›å»ºç»“æœåˆ—è¡¨
        results = []
        
        # å¯åŠ¨å…¨å±€è¶…æ—¶è®¡æ—¶å™¨
        global_timeout_timer = threading.Timer(self.config['global_timeout'], self._handle_global_timeout)
        global_timeout_timer.daemon = True
        global_timeout_timer.start()
        
        # å¯åŠ¨çŠ¶æ€ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self._status_monitor)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        try:
            # ä½¿ç”¨ThreadPoolExecutorå¹¶å‘æ‰§è¡Œæµ‹è¯•
            with ThreadPoolExecutor(max_workers=min(self.config['max_workers'], len(models_to_test))) as executor:
                # æäº¤æ‰€æœ‰æµ‹è¯•ä»»åŠ¡
                future_to_model = {executor.submit(self._test_model_once, model_id): model_id for model_id in models_to_test}
                
                # æ”¶é›†ç»“æœ
                for future in future_to_model:
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        model_id = future_to_model[future]
                        error_info = parse_exception(e)
                        results.append({
                            'model_id': model_id,
                            'provider_name': self.provider_name,
                            'timestamp': format_timestamp(),
                            'status': 'error',
                            'latency': 0,
                            'retries': 0,
                            'error_code': error_info['error_code'],
                            'error_category': error_info['error_category'],
                            'solution': error_info['solution'],
                            'response': str(e)
                        })
        
        finally:
            # åœæ­¢å…¨å±€è¶…æ—¶è®¡æ—¶å™¨
            global_timeout_timer.cancel()
            
            # è®¾ç½®åœæ­¢æ ‡å¿—ï¼Œç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            self.should_stop = True
            monitor_thread.join(timeout=1.0)
            
            # æ¸…ç©ºæ§åˆ¶å°å¹¶æ˜¾ç¤ºç»“æœ
            clear_console()
            self._show_results(results)
            
            # ç”ŸæˆæŠ¥å‘Š
            report_file = self.generate_report(results)
            if report_file:
                print(f"\næµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    def _test_model_once(self, model_id: str) -> Dict[str, Any]:
        """
        æµ‹è¯•å•ä¸ªæ¨¡å‹
        
        Args:
            model_id (str): å½“å‰æœåŠ¡å•†çš„å®é™…æ¨¡å‹ID
            
        Returns:
            Dict[str, Any]: åŒ…å«è¯¦ç»†æµ‹è¯•ç»“æœçš„å­—å…¸
        """
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        result = {
            'model_id': model_id,
            'provider_name': self.provider_name,
            'timestamp': format_timestamp(),
            'status': 'pending',
            'latency': 0,
            'retries': 0,
            'error_code': '',
            'error_category': '',
            'solution': '',
            'response': ''
        }
        
        # æ£€æŸ¥å…¨å±€åœæ­¢æ ‡å¿—
        if self.should_stop:
            result['status'] = 'global_timeout'
            return result
        
        # æ„å»ºè¯·æ±‚è´Ÿè½½
        payload = self.config['test_prompt'].copy()
        payload['model'] = model_id
        
        # ç¡®å®šAPIç«¯ç‚¹
        endpoint = '/v1/chat/completions'
        if self.api_type == 'anthropic':
            endpoint = '/v1/messages'
        elif self.api_type == 'google-vertex-ai':
            # Google Vertex AIå¯èƒ½æœ‰ä¸åŒçš„ç«¯ç‚¹æ ¼å¼
            endpoint = '/v1/models/{model}:predict'.format(model=model_id)
        
        # æ›´æ–°æ´»åŠ¨ä»»åŠ¡çŠ¶æ€
        with self.status_lock:
            self.active_tasks[model_id] = {
                'status': 'starting',
                'start_time': time.time(),
                'retries': 0,
                'latency': 0
            }
        
        # é‡è¯•é€»è¾‘
        retry_count = 0
        max_retries = self.config['max_retries']
        
        while retry_count <= max_retries:
            # æ£€æŸ¥å…¨å±€åœæ­¢æ ‡å¿—
            if self.should_stop:
                result['status'] = 'global_timeout'
                break
            
            # æ›´æ–°é‡è¯•è®¡æ•°
            result['retries'] = retry_count
            
            # æ›´æ–°æ´»åŠ¨ä»»åŠ¡çŠ¶æ€
            with self.status_lock:
                self.active_tasks[model_id]['status'] = 'running' if retry_count == 0 else f'retry_{retry_count}'
                self.active_tasks[model_id]['retries'] = retry_count
            
            try:
                # è§£æURL
                parsed_url = urlparse(self.base_url)
                conn = http.client.HTTPSConnection(parsed_url.netloc, timeout=self.config['request_timeout'])
                
                # å‘é€è¯·æ±‚
                start_time = time.time()
                conn.request('POST', endpoint, body=json.dumps(payload), headers=self.headers)
                response = conn.getresponse()
                response_data = response.read().decode('utf-8')
                end_time = time.time()
                
                # è®¡ç®—å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
                latency = int((end_time - start_time) * 1000)
                result['latency'] = latency
                
                # æ›´æ–°æ´»åŠ¨ä»»åŠ¡çŠ¶æ€
                with self.status_lock:
                    self.active_tasks[model_id]['latency'] = latency
                
                # å¤„ç†å“åº”
                if response.status == 200:
                    # æˆåŠŸ
                    result['status'] = 'success'
                    result['response'] = response_data
                    break
                else:
                    # HTTPé”™è¯¯
                    error_info = parse_error(response.status, response_data)
                    result['status'] = f"{response.status}/{error_info['error_code']}"
                    result['error_code'] = error_info['error_code']
                    result['error_category'] = error_info['error_category']
                    result['solution'] = error_info['solution']
                    result['response'] = response_data
                    
                    # æŸäº›é”™è¯¯ä¸åº”é‡è¯•
                    if response.status in [400, 401, 403, 404]:
                        break
            
            except Exception as e:
                # Pythonå¼‚å¸¸
                error_info = parse_exception(e)
                result['status'] = f"exception/{error_info['error_code']}"
                result['error_code'] = error_info['error_code']
                result['error_category'] = error_info['error_category']
                result['solution'] = error_info['solution']
                result['response'] = str(e)
            
            # å¢åŠ é‡è¯•è®¡æ•°
            retry_count += 1
            
            # å¦‚æœè¿˜æœ‰é‡è¯•æ¬¡æ•°ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•ï¼ˆç®€å•çš„æŒ‡æ•°é€€é¿ï¼‰
            if retry_count <= max_retries:
                backoff_time = min(2 ** retry_count, 10)  # æœ€å¤šç­‰å¾…10ç§’
                time.sleep(backoff_time)
        
        # æµ‹è¯•ç»“æŸï¼Œä»æ´»åŠ¨ä»»åŠ¡ä¸­ç§»é™¤
        with self.status_lock:
            if model_id in self.active_tasks:
                del self.active_tasks[model_id]
        
        # åŸå­åœ°å¢åŠ å·²å®Œæˆä»»åŠ¡è®¡æ•°
        with self.progress_lock:
            self.completed_tasks += 1
        
        return result
    
    def _status_monitor(self) -> None:
        """
        å®æ—¶çŠ¶æ€ç›‘æ§
        
        åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼Œå®šæœŸåˆ·æ–°æ§åˆ¶å°æ˜¾ç¤ºå½“å‰æµ‹è¯•çŠ¶æ€
        """
        while not self.should_stop:
            # æ¸…ç©ºæ§åˆ¶å°
            clear_console()
            
            # è·å–å½“å‰çŠ¶æ€çš„å¿«ç…§
            with self.status_lock:
                active_tasks_snapshot = self.active_tasks.copy()
            
            with self.progress_lock:
                completed = self.completed_tasks
                total = self.total_tasks
            
            # æ˜¾ç¤ºå½“å‰å¹¶å‘æ•°å’Œè¿›åº¦
            print(f"æœåŠ¡å•†: {self.provider_name}")
            print(f"å½“å‰å¹¶å‘æ•°: {len(active_tasks_snapshot)}/{self.config['max_workers']}")
            print(create_progress_bar(completed, total))
            
            # æ˜¾ç¤ºå½“å‰æµ‹è¯•ä¸­çš„æ¨¡å‹
            if active_tasks_snapshot:
                print("\nå½“å‰æµ‹è¯•ä¸­çš„æ¨¡å‹:")
                for model_id, task_info in active_tasks_snapshot.items():
                    status_icon = "ğŸ”„" if task_info['status'] == 'running' else "â¹ï¸"
                    latency = task_info['latency']
                    retries = task_info['retries']
                    print(f"{status_icon} {model_id} ({self.provider_name}) - {latency}ms - é‡è¯•: {retries}")
            
            # ä¼‘çœ ä¸€æ®µæ—¶é—´
            time.sleep(self.config['status_refresh'])
    
    def _handle_global_timeout(self) -> None:
        """
        å¤„ç†å…¨å±€è¶…æ—¶
        
        ç”±å…¨å±€è¶…æ—¶è®¡æ—¶å™¨è°ƒç”¨ï¼Œè®¾ç½®åœæ­¢æ ‡å¿—
        """
        print(f"\nè­¦å‘Š: å·²è¾¾åˆ°å…¨å±€è¶…æ—¶é™åˆ¶ ({self.config['global_timeout']}ç§’)ï¼Œæ­£åœ¨åœæ­¢æµ‹è¯•...")
        self.should_stop = True
    
    def _show_results(self, results: List[Dict[str, Any]]) -> None:
        """
        æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        
        Args:
            results (List[Dict[str, Any]]): æµ‹è¯•ç»“æœåˆ—è¡¨
        """
        print("\næµ‹è¯•ç»“æœæ‘˜è¦:")
        print("-" * 80)
        
        success_count = 0
        failure_count = 0
        
        for result in results:
            if result['status'] == 'success':
                status_icon = "âœ…"
                success_count += 1
            else:
                status_icon = "âŒ"
                failure_count += 1
            
            print(f"{status_icon} {result['provider_name']} - {result['model_id']} - çŠ¶æ€: {result['status']} - å»¶è¿Ÿ: {result['latency']}ms - é‡è¯•: {result['retries']}")
        
        print("-" * 80)
        print(f"æ€»è®¡: {len(results)} ä¸ªæ¨¡å‹æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸ: {success_count}ï¼Œå¤±è´¥: {failure_count}")
    
    def generate_report(self, results: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        
        Args:
            results (List[Dict[str, Any]]): æµ‹è¯•ç»“æœåˆ—è¡¨
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
            timestamp = time.time()
            report_filename = generate_filename("model_test_report", "csv", timestamp)
            
            # ç¡®ä¿dataç›®å½•å­˜åœ¨
            import os
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            data_dir = os.path.join(base_dir, 'data')
            os.makedirs(data_dir, exist_ok=True)
            
            report_path = os.path.join(data_dir, report_filename)
            
            # å®šä¹‰CSVåˆ—
            fieldnames = [
                'timestamp',
                'provider_name',
                'category',
                'model_id',
                'status',
                'error_code',
                'error_category',
                'solution',
                'latency_ms',
                'retries',
                'response_content'
            ]
            
            # å†™å…¥CSVæ–‡ä»¶
            with open(report_path, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for result in results:
                    # æŸ¥æ‰¾æ¨¡å‹åˆ†ç±»ï¼ˆå¦‚æœæœ‰ï¼‰
                    category = ''
                    for cat, models in self.categories.items():
                        if result['model_id'] in models:
                            category = cat
                            break
                    
                    # å†™å…¥è¡Œ
                    writer.writerow({
                        'timestamp': result['timestamp'],
                        'provider_name': result['provider_name'],
                        'category': category,
                        'model_id': result['model_id'],
                        'status': result['status'],
                        'error_code': result.get('error_code', ''),
                        'error_category': result.get('error_category', ''),
                        'solution': result.get('solution', ''),
                        'latency_ms': result['latency'],
                        'retries': result['retries'],
                        'response_content': result['response']
                    })
            
            return report_path
        
        except Exception as e:
            print(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return ""